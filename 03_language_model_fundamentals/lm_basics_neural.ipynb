{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b45a2c",
   "metadata": {},
   "source": [
    "> **Note:** This notebook is my personal practice notebook on Feedforward neural language model\n",
    ">  \n",
    "> Iâ€™m following along with the course materials and using ideas/code inspired by:\n",
    "> \n",
    "> - [CMU ANLP Course Page](https://cmu-l3.github.io/anlp-spring2025/)  \n",
    ">   *(Lecture 3: Language Modeling Fundamentals, Spring 2025)*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5512f9",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "\n",
    "1. [Build the Dataset](#Build-the-dataset)\n",
    "2. [Define the Model](#Define-the-model)\n",
    "3. [Training](#Training)\n",
    "4. [Conditional Generation](#Conditional-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51222e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import random\n",
    "from torch import nn, optim\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35fba1",
   "metadata": {},
   "source": [
    "### Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2b41dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "# Understanding the dataset\n",
    "data=open('names.txt').read().splitlines()\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619178c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the letters by mapping it to an index\n",
    "\n",
    "token_to_index = {token: i for i,token in enumerate('abcdefghijklmnopqrstuvwxyz')}\n",
    "token_to_index['[S]'] = 26 # Appending [S] token\n",
    "index_to_token = {i:token for token,i in token_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d0f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Dataset class\n",
    "# Our dataset consists of x, y pairs, where x is a (n-1) token context and y is a token\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Dataset class for building context-target pairs from a sequence of tokens.\n",
    "    \"\"\"\n",
    "    def __init__(self, context_size:int, token_to_index:Dict[str, int]):\n",
    "        self.context_size = context_size\n",
    "        self.token_to_index = token_to_index\n",
    "\n",
    "    def build_dataset(self, data:List[str]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Build the dataset of context-target pairs.\n",
    "\n",
    "        Args:\n",
    "            data (List[str]): List of string sequences.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]:\n",
    "                X: Tensor of shape (num_samples, context_size)\n",
    "                Y: Tensor of shape (num_samples,)\n",
    "        \"\"\" \n",
    "        X, Y = [], []\n",
    "        for item in data:\n",
    "            context = [self.token_to_index['[S]']] * self.context_size\n",
    "            tokens = list(item) + ['[S]'] # Appending an [S] token to mark the end of the sequence.\n",
    "            for token in tokens:\n",
    "                X.append(context)\n",
    "                Y.append(self.token_to_index[token])\n",
    "                context = context[1:] + [self.token_to_index[token]]\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53bf919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the datasets\n",
    "\n",
    "# shuffle the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# train/val/test split as 80/10/10\n",
    "n1 = int(0.8 * len(data))\n",
    "n2 = int(0.9 * len(data))\n",
    "\n",
    "context_size = 5 # taking last five characters as a context\n",
    "dataset = Dataset(context_size=context_size, token_to_index=token_to_index)\n",
    "x_train, y_train = dataset.build_dataset(data[:n1])\n",
    "x_val, y_val = dataset.build_dataset(data[n1:n2])\n",
    "x_test, y_test = dataset.build_dataset(data[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53438c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26, 26, 26, 26, 26],\n",
      "        [26, 26, 26, 26, 11],\n",
      "        [26, 26, 26, 11, 20],\n",
      "        [26, 26, 11, 20,  0],\n",
      "        [26, 11, 20,  0, 13],\n",
      "        [11, 20,  0, 13, 13],\n",
      "        [26, 26, 26, 26, 26],\n",
      "        [26, 26, 26, 26, 18],\n",
      "        [26, 26, 26, 18,  7],\n",
      "        [26, 26, 18,  7,  0]])\n",
      "tensor([11, 20,  0, 13, 13, 26, 18,  7,  0,  8])\n"
     ]
    }
   ],
   "source": [
    "# Understanding the created dataset\n",
    "print(x_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10872f",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20d8986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLM(nn.Module):\n",
    "    '''Defining the Multi Layer Perceptro based Language model'''\n",
    "    def __init__(self, vocab_size:int, embedding_size:int, context_size:int, hidden_size:int):\n",
    "        super(MLPLM, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "        self.fc1 = nn.Linear(in_features=context_size*embedding_size, out_features=hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "694a89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPLM(\n",
    "    vocab_size=len(token_to_index),\n",
    "    embedding_size=64,\n",
    "    context_size=5,\n",
    "    hidden_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "32643912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 27])\n"
     ]
    }
   ],
   "source": [
    "output=model(x_train[:2])\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf81443",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fbd7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "model = MLPLM(\n",
    "    vocab_size=len(token_to_index),\n",
    "    embedding_size=64,\n",
    "    context_size=5,\n",
    "    hidden_size=32\n",
    ")\n",
    "\n",
    "# Hyper parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55ac12c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Average loss is 2.46578948694363\n",
      "epoch 1: Average loss is 2.367275342753059\n",
      "epoch 2: Average loss is 2.3490918047595444\n",
      "epoch 3: Average loss is 2.3385062630971274\n",
      "epoch 4: Average loss is 2.3324026145642263\n",
      "epoch 5: Average loss is 2.327908363802391\n",
      "epoch 6: Average loss is 2.324646507271549\n",
      "epoch 7: Average loss is 2.322029471815678\n",
      "epoch 8: Average loss is 2.319872084542325\n",
      "epoch 9: Average loss is 2.317828746783106\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        x_batch = x_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / (len(x_train)// batch_size)\n",
    "    print(f'epoch {epoch}: Average loss is {average_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d0e81",
   "metadata": {},
   "source": [
    "### Conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24c1b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(model, context, max_length=25):\n",
    "    model.eval()\n",
    "    output = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        context = torch.tensor(context).unsqueeze(0)\n",
    "        for _ in range(max_length):\n",
    "            logits = model(context)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            token = torch.multinomial(probs, num_samples=1) # intuition: Instead of just multinomial, probably use topk with multinomial for better results\n",
    "            context = torch.cat([context[:, 1:], token], dim=-1)\n",
    "\n",
    "            output.append(index_to_token[token.item()])\n",
    "            if index_to_token[token.item()] == '[S]':\n",
    "                return ''.join(output)[:-3]\n",
    "    return ''.join(output)[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "838d8db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sockenmene\n",
      "sogbabel\n",
      "somiacausyn\n",
      "sofiquiat\n"
     ]
    }
   ],
   "source": [
    "prompts = ['so', 'so', 'so', 'so']\n",
    "\n",
    "for prompt in prompts:\n",
    "    output = generator(model, ([token_to_index['[S]']] * (context_size-len(prompt))) + [token_to_index[c] for c in prompt])\n",
    "    print(prompt+output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044d9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
